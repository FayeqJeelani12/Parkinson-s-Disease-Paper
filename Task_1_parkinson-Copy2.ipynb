{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>PPE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>numPulses</th>\n",
       "      <th>numPeriodsPulses</th>\n",
       "      <th>meanPeriodPulses</th>\n",
       "      <th>stdDevPeriodPulses</th>\n",
       "      <th>locPctJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tqwt_kurtosisValue_dec_28</th>\n",
       "      <th>tqwt_kurtosisValue_dec_29</th>\n",
       "      <th>tqwt_kurtosisValue_dec_30</th>\n",
       "      <th>tqwt_kurtosisValue_dec_31</th>\n",
       "      <th>tqwt_kurtosisValue_dec_32</th>\n",
       "      <th>tqwt_kurtosisValue_dec_33</th>\n",
       "      <th>tqwt_kurtosisValue_dec_34</th>\n",
       "      <th>tqwt_kurtosisValue_dec_35</th>\n",
       "      <th>tqwt_kurtosisValue_dec_36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85247</td>\n",
       "      <td>0.71826</td>\n",
       "      <td>0.57227</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.00218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5620</td>\n",
       "      <td>2.6445</td>\n",
       "      <td>3.8686</td>\n",
       "      <td>4.2105</td>\n",
       "      <td>5.1221</td>\n",
       "      <td>4.4625</td>\n",
       "      <td>2.6202</td>\n",
       "      <td>3.0004</td>\n",
       "      <td>18.9405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76686</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.53966</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5589</td>\n",
       "      <td>3.6107</td>\n",
       "      <td>23.5155</td>\n",
       "      <td>14.1962</td>\n",
       "      <td>11.0261</td>\n",
       "      <td>9.5082</td>\n",
       "      <td>6.5245</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>45.1780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85083</td>\n",
       "      <td>0.67604</td>\n",
       "      <td>0.58982</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5643</td>\n",
       "      <td>2.3308</td>\n",
       "      <td>9.4959</td>\n",
       "      <td>10.7458</td>\n",
       "      <td>11.0177</td>\n",
       "      <td>4.8066</td>\n",
       "      <td>2.9199</td>\n",
       "      <td>3.1495</td>\n",
       "      <td>4.7666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41121</td>\n",
       "      <td>0.79672</td>\n",
       "      <td>0.59257</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7805</td>\n",
       "      <td>3.5664</td>\n",
       "      <td>5.2558</td>\n",
       "      <td>14.0403</td>\n",
       "      <td>4.2235</td>\n",
       "      <td>4.6857</td>\n",
       "      <td>4.8460</td>\n",
       "      <td>6.2650</td>\n",
       "      <td>4.0603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32790</td>\n",
       "      <td>0.79782</td>\n",
       "      <td>0.53028</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1727</td>\n",
       "      <td>5.8416</td>\n",
       "      <td>6.0805</td>\n",
       "      <td>5.7621</td>\n",
       "      <td>7.7817</td>\n",
       "      <td>11.6891</td>\n",
       "      <td>8.2103</td>\n",
       "      <td>5.0559</td>\n",
       "      <td>6.1164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50780</td>\n",
       "      <td>0.78744</td>\n",
       "      <td>0.65451</td>\n",
       "      <td>226</td>\n",
       "      <td>221</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.00783</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8025</td>\n",
       "      <td>5.0734</td>\n",
       "      <td>7.0166</td>\n",
       "      <td>5.9966</td>\n",
       "      <td>5.2065</td>\n",
       "      <td>7.4246</td>\n",
       "      <td>3.4153</td>\n",
       "      <td>3.5046</td>\n",
       "      <td>3.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76095</td>\n",
       "      <td>0.62145</td>\n",
       "      <td>0.54543</td>\n",
       "      <td>322</td>\n",
       "      <td>321</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>...</td>\n",
       "      <td>117.2678</td>\n",
       "      <td>75.3156</td>\n",
       "      <td>32.0478</td>\n",
       "      <td>7.7060</td>\n",
       "      <td>3.1060</td>\n",
       "      <td>4.6206</td>\n",
       "      <td>12.8353</td>\n",
       "      <td>13.8300</td>\n",
       "      <td>7.7693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83671</td>\n",
       "      <td>0.62079</td>\n",
       "      <td>0.51179</td>\n",
       "      <td>318</td>\n",
       "      <td>317</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.00282</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8564</td>\n",
       "      <td>11.8909</td>\n",
       "      <td>7.2891</td>\n",
       "      <td>4.3682</td>\n",
       "      <td>3.6443</td>\n",
       "      <td>5.9610</td>\n",
       "      <td>11.7552</td>\n",
       "      <td>18.0927</td>\n",
       "      <td>5.0448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80826</td>\n",
       "      <td>0.61766</td>\n",
       "      <td>0.50447</td>\n",
       "      <td>318</td>\n",
       "      <td>317</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.00161</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2640</td>\n",
       "      <td>6.3993</td>\n",
       "      <td>4.4165</td>\n",
       "      <td>4.2662</td>\n",
       "      <td>3.6357</td>\n",
       "      <td>3.7346</td>\n",
       "      <td>2.9394</td>\n",
       "      <td>3.6216</td>\n",
       "      <td>3.8430</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85302</td>\n",
       "      <td>0.62247</td>\n",
       "      <td>0.54855</td>\n",
       "      <td>493</td>\n",
       "      <td>492</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6796</td>\n",
       "      <td>2.0474</td>\n",
       "      <td>2.8117</td>\n",
       "      <td>3.5070</td>\n",
       "      <td>3.2727</td>\n",
       "      <td>3.8415</td>\n",
       "      <td>3.9439</td>\n",
       "      <td>5.8807</td>\n",
       "      <td>38.7211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  gender      PPE      DFA     RPDE  numPulses  numPeriodsPulses  \\\n",
       "0   0       1  0.85247  0.71826  0.57227        240               239   \n",
       "1   0       1  0.76686  0.69481  0.53966        234               233   \n",
       "2   0       1  0.85083  0.67604  0.58982        232               231   \n",
       "3   1       0  0.41121  0.79672  0.59257        178               177   \n",
       "4   1       0  0.32790  0.79782  0.53028        236               235   \n",
       "5   1       0  0.50780  0.78744  0.65451        226               221   \n",
       "6   2       1  0.76095  0.62145  0.54543        322               321   \n",
       "7   2       1  0.83671  0.62079  0.51179        318               317   \n",
       "8   2       1  0.80826  0.61766  0.50447        318               317   \n",
       "9   3       0  0.85302  0.62247  0.54855        493               492   \n",
       "\n",
       "   meanPeriodPulses  stdDevPeriodPulses  locPctJitter  ...    \\\n",
       "0          0.008064            0.000087       0.00218  ...     \n",
       "1          0.008258            0.000073       0.00195  ...     \n",
       "2          0.008340            0.000060       0.00176  ...     \n",
       "3          0.010858            0.000183       0.00419  ...     \n",
       "4          0.008162            0.002669       0.00535  ...     \n",
       "5          0.007631            0.002696       0.00783  ...     \n",
       "6          0.005991            0.000107       0.00222  ...     \n",
       "7          0.006074            0.000136       0.00282  ...     \n",
       "8          0.006057            0.000069       0.00161  ...     \n",
       "9          0.003910            0.000040       0.00075  ...     \n",
       "\n",
       "   tqwt_kurtosisValue_dec_28  tqwt_kurtosisValue_dec_29  \\\n",
       "0                     1.5620                     2.6445   \n",
       "1                     1.5589                     3.6107   \n",
       "2                     1.5643                     2.3308   \n",
       "3                     3.7805                     3.5664   \n",
       "4                     6.1727                     5.8416   \n",
       "5                     4.8025                     5.0734   \n",
       "6                   117.2678                    75.3156   \n",
       "7                     3.8564                    11.8909   \n",
       "8                     2.2640                     6.3993   \n",
       "9                     1.6796                     2.0474   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_30  tqwt_kurtosisValue_dec_31  \\\n",
       "0                     3.8686                     4.2105   \n",
       "1                    23.5155                    14.1962   \n",
       "2                     9.4959                    10.7458   \n",
       "3                     5.2558                    14.0403   \n",
       "4                     6.0805                     5.7621   \n",
       "5                     7.0166                     5.9966   \n",
       "6                    32.0478                     7.7060   \n",
       "7                     7.2891                     4.3682   \n",
       "8                     4.4165                     4.2662   \n",
       "9                     2.8117                     3.5070   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_32  tqwt_kurtosisValue_dec_33  \\\n",
       "0                     5.1221                     4.4625   \n",
       "1                    11.0261                     9.5082   \n",
       "2                    11.0177                     4.8066   \n",
       "3                     4.2235                     4.6857   \n",
       "4                     7.7817                    11.6891   \n",
       "5                     5.2065                     7.4246   \n",
       "6                     3.1060                     4.6206   \n",
       "7                     3.6443                     5.9610   \n",
       "8                     3.6357                     3.7346   \n",
       "9                     3.2727                     3.8415   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_34  tqwt_kurtosisValue_dec_35  \\\n",
       "0                     2.6202                     3.0004   \n",
       "1                     6.5245                     6.3431   \n",
       "2                     2.9199                     3.1495   \n",
       "3                     4.8460                     6.2650   \n",
       "4                     8.2103                     5.0559   \n",
       "5                     3.4153                     3.5046   \n",
       "6                    12.8353                    13.8300   \n",
       "7                    11.7552                    18.0927   \n",
       "8                     2.9394                     3.6216   \n",
       "9                     3.9439                     5.8807   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_36  class  \n",
       "0                    18.9405      1  \n",
       "1                    45.1780      1  \n",
       "2                     4.7666      1  \n",
       "3                     4.0603      1  \n",
       "4                     6.1164      1  \n",
       "5                     3.2250      1  \n",
       "6                     7.7693      1  \n",
       "7                     5.0448      1  \n",
       "8                     3.8430      1  \n",
       "9                    38.7211      1  \n",
       "\n",
       "[10 rows x 755 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset \n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "df = pd.read_csv(\"pd_speech_features_1.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1         2         3         4         5         6         7    \\\n",
      "0  0.000000  1.0  0.936278  0.565310  0.583000  0.262983  0.263274  0.548552   \n",
      "1  0.000000  1.0  0.837434  0.489455  0.537514  0.256354  0.256637  0.566485   \n",
      "2  0.000000  1.0  0.934385  0.428738  0.607479  0.254144  0.254425  0.573975   \n",
      "3  0.003984  0.0  0.426804  0.819111  0.611315  0.194475  0.194690  0.805881   \n",
      "4  0.003984  0.0  0.330615  0.822669  0.524431  0.258564  0.258850  0.557581   \n",
      "5  0.003984  0.0  0.538326  0.789092  0.697711  0.247514  0.243363  0.508737   \n",
      "6  0.007968  1.0  0.830610  0.252151  0.545562  0.353591  0.353982  0.357683   \n",
      "7  0.007968  1.0  0.918082  0.250016  0.498640  0.349171  0.349558  0.365315   \n",
      "8  0.007968  1.0  0.885234  0.239891  0.488430  0.349171  0.349558  0.363780   \n",
      "9  0.011952  0.0  0.936913  0.255451  0.549914  0.542541  0.543142  0.166057   \n",
      "\n",
      "        8         9   ...        745       746       747       748       749  \\\n",
      "0  0.021947  0.071532 ...   0.000219  0.005515  0.019054  0.024520  0.039777   \n",
      "1  0.018001  0.063181 ...   0.000206  0.010303  0.182833  0.123920  0.110245   \n",
      "2  0.014344  0.056282 ...   0.000229  0.003960  0.065964  0.089574  0.110145   \n",
      "3  0.049580  0.144517 ...   0.009530  0.010084  0.030618  0.122368  0.029052   \n",
      "4  0.765643  0.186638 ...   0.019569  0.021359  0.037492  0.039965  0.071521   \n",
      "5  0.773569  0.276688 ...   0.013819  0.017552  0.045296  0.042300  0.040784   \n",
      "6  0.027842  0.072985 ...   0.485809  0.365666  0.253959  0.059315  0.015713   \n",
      "7  0.036043  0.094771 ...   0.009848  0.051339  0.047568  0.026090  0.022138   \n",
      "8  0.016907  0.050835 ...   0.003165  0.024123  0.023621  0.025075  0.022036   \n",
      "9  0.008439  0.019608 ...   0.000713  0.002556  0.010243  0.017517  0.017703   \n",
      "\n",
      "        750       751       752       753  754  \n",
      "0  0.039411  0.012611  0.018790  0.107598  1.0  \n",
      "1  0.109584  0.077525  0.078923  0.277905  1.0  \n",
      "2  0.044197  0.017594  0.021472  0.015595  1.0  \n",
      "3  0.042515  0.049618  0.077518  0.011011  1.0  \n",
      "4  0.139915  0.105554  0.055767  0.024357  1.0  \n",
      "5  0.080607  0.025831  0.027860  0.005589  1.0  \n",
      "6  0.041610  0.182451  0.213608  0.035086  1.0  \n",
      "7  0.060252  0.164492  0.290291  0.017401  1.0  \n",
      "8  0.029288  0.017918  0.029965  0.009600  1.0  \n",
      "9  0.030775  0.034619  0.070605  0.235994  1.0  \n",
      "\n",
      "[10 rows x 755 columns]\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = df.values \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "d_f = pd.DataFrame(x_scaled)\n",
    "print(d_f.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756, 755)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_f.to_csv(r'C:\\Users\\Syed Fayeq Jeelani\\normalized_pd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_frame = pd.read_csv(\"normalized_pd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_f.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936278</td>\n",
       "      <td>0.565310</td>\n",
       "      <td>0.583000</td>\n",
       "      <td>0.262983</td>\n",
       "      <td>0.263274</td>\n",
       "      <td>0.548552</td>\n",
       "      <td>0.021947</td>\n",
       "      <td>0.071532</td>\n",
       "      <td>0.066124</td>\n",
       "      <td>0.058930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058912</td>\n",
       "      <td>0.213827</td>\n",
       "      <td>0.223627</td>\n",
       "      <td>0.210444</td>\n",
       "      <td>0.157709</td>\n",
       "      <td>0.172879</td>\n",
       "      <td>0.210485</td>\n",
       "      <td>0.930261</td>\n",
       "      <td>0.046782</td>\n",
       "      <td>0.549743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837434</td>\n",
       "      <td>0.489455</td>\n",
       "      <td>0.537514</td>\n",
       "      <td>0.256354</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>0.566485</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.063181</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.045331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045921</td>\n",
       "      <td>0.198814</td>\n",
       "      <td>0.216334</td>\n",
       "      <td>0.156103</td>\n",
       "      <td>0.166871</td>\n",
       "      <td>0.222206</td>\n",
       "      <td>0.156147</td>\n",
       "      <td>0.963248</td>\n",
       "      <td>0.022804</td>\n",
       "      <td>0.629066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.934385</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607479</td>\n",
       "      <td>0.254144</td>\n",
       "      <td>0.254425</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.014344</td>\n",
       "      <td>0.056282</td>\n",
       "      <td>0.054786</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050151</td>\n",
       "      <td>0.378237</td>\n",
       "      <td>0.408362</td>\n",
       "      <td>0.374253</td>\n",
       "      <td>0.311323</td>\n",
       "      <td>0.279111</td>\n",
       "      <td>0.374260</td>\n",
       "      <td>0.940123</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.507133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.426804</td>\n",
       "      <td>0.819111</td>\n",
       "      <td>0.611315</td>\n",
       "      <td>0.194475</td>\n",
       "      <td>0.194690</td>\n",
       "      <td>0.805881</td>\n",
       "      <td>0.049580</td>\n",
       "      <td>0.144517</td>\n",
       "      <td>0.175196</td>\n",
       "      <td>0.133273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133233</td>\n",
       "      <td>0.196155</td>\n",
       "      <td>0.228488</td>\n",
       "      <td>0.162001</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.159672</td>\n",
       "      <td>0.162018</td>\n",
       "      <td>0.924253</td>\n",
       "      <td>0.054377</td>\n",
       "      <td>0.577325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330615</td>\n",
       "      <td>0.822669</td>\n",
       "      <td>0.524431</td>\n",
       "      <td>0.258564</td>\n",
       "      <td>0.258850</td>\n",
       "      <td>0.557581</td>\n",
       "      <td>0.765643</td>\n",
       "      <td>0.186638</td>\n",
       "      <td>0.168159</td>\n",
       "      <td>0.148685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149245</td>\n",
       "      <td>0.202659</td>\n",
       "      <td>0.213904</td>\n",
       "      <td>0.202422</td>\n",
       "      <td>0.149058</td>\n",
       "      <td>0.189117</td>\n",
       "      <td>0.202464</td>\n",
       "      <td>0.942339</td>\n",
       "      <td>0.034847</td>\n",
       "      <td>0.567561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.538326</td>\n",
       "      <td>0.789092</td>\n",
       "      <td>0.697711</td>\n",
       "      <td>0.247514</td>\n",
       "      <td>0.243363</td>\n",
       "      <td>0.508737</td>\n",
       "      <td>0.773569</td>\n",
       "      <td>0.276688</td>\n",
       "      <td>0.230709</td>\n",
       "      <td>0.208522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209063</td>\n",
       "      <td>0.290284</td>\n",
       "      <td>0.301896</td>\n",
       "      <td>0.272885</td>\n",
       "      <td>0.222768</td>\n",
       "      <td>0.231444</td>\n",
       "      <td>0.272896</td>\n",
       "      <td>0.773870</td>\n",
       "      <td>0.179311</td>\n",
       "      <td>0.412815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.830610</td>\n",
       "      <td>0.252151</td>\n",
       "      <td>0.545562</td>\n",
       "      <td>0.353591</td>\n",
       "      <td>0.353982</td>\n",
       "      <td>0.357683</td>\n",
       "      <td>0.027842</td>\n",
       "      <td>0.072985</td>\n",
       "      <td>0.049313</td>\n",
       "      <td>0.030825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031118</td>\n",
       "      <td>0.104193</td>\n",
       "      <td>0.108410</td>\n",
       "      <td>0.095549</td>\n",
       "      <td>0.079648</td>\n",
       "      <td>0.116804</td>\n",
       "      <td>0.095570</td>\n",
       "      <td>0.963839</td>\n",
       "      <td>0.019876</td>\n",
       "      <td>0.539439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.918082</td>\n",
       "      <td>0.250016</td>\n",
       "      <td>0.498640</td>\n",
       "      <td>0.349171</td>\n",
       "      <td>0.349558</td>\n",
       "      <td>0.365315</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.094771</td>\n",
       "      <td>0.064169</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>0.230886</td>\n",
       "      <td>0.234322</td>\n",
       "      <td>0.205568</td>\n",
       "      <td>0.188165</td>\n",
       "      <td>0.231227</td>\n",
       "      <td>0.205609</td>\n",
       "      <td>0.971309</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.591180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.885234</td>\n",
       "      <td>0.239891</td>\n",
       "      <td>0.488430</td>\n",
       "      <td>0.349171</td>\n",
       "      <td>0.349558</td>\n",
       "      <td>0.363780</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>0.050835</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>0.022665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022961</td>\n",
       "      <td>0.087012</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.081865</td>\n",
       "      <td>0.068847</td>\n",
       "      <td>0.096020</td>\n",
       "      <td>0.081913</td>\n",
       "      <td>0.982944</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>0.656934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.936913</td>\n",
       "      <td>0.255451</td>\n",
       "      <td>0.549914</td>\n",
       "      <td>0.542541</td>\n",
       "      <td>0.543142</td>\n",
       "      <td>0.166057</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.205114</td>\n",
       "      <td>0.221196</td>\n",
       "      <td>0.185357</td>\n",
       "      <td>0.149928</td>\n",
       "      <td>0.201819</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.988096</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.690223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2         3         4         5         6         7         8   \\\n",
       "0  0.936278  0.565310  0.583000  0.262983  0.263274  0.548552  0.021947   \n",
       "1  0.837434  0.489455  0.537514  0.256354  0.256637  0.566485  0.018001   \n",
       "2  0.934385  0.428738  0.607479  0.254144  0.254425  0.573975  0.014344   \n",
       "3  0.426804  0.819111  0.611315  0.194475  0.194690  0.805881  0.049580   \n",
       "4  0.330615  0.822669  0.524431  0.258564  0.258850  0.557581  0.765643   \n",
       "5  0.538326  0.789092  0.697711  0.247514  0.243363  0.508737  0.773569   \n",
       "6  0.830610  0.252151  0.545562  0.353591  0.353982  0.357683  0.027842   \n",
       "7  0.918082  0.250016  0.498640  0.349171  0.349558  0.365315  0.036043   \n",
       "8  0.885234  0.239891  0.488430  0.349171  0.349558  0.363780  0.016907   \n",
       "9  0.936913  0.255451  0.549914  0.542541  0.543142  0.166057  0.008439   \n",
       "\n",
       "         9         10        11    ...           13        14        15  \\\n",
       "0  0.071532  0.066124  0.058930    ...     0.058912  0.213827  0.223627   \n",
       "1  0.063181  0.060259  0.045331    ...     0.045921  0.198814  0.216334   \n",
       "2  0.056282  0.054786  0.049864    ...     0.050151  0.378237  0.408362   \n",
       "3  0.144517  0.175196  0.133273    ...     0.133233  0.196155  0.228488   \n",
       "4  0.186638  0.168159  0.148685    ...     0.149245  0.202659  0.213904   \n",
       "5  0.276688  0.230709  0.208522    ...     0.209063  0.290284  0.301896   \n",
       "6  0.072985  0.049313  0.030825    ...     0.031118  0.104193  0.108410   \n",
       "7  0.094771  0.064169  0.029012    ...     0.029607  0.230886  0.234322   \n",
       "8  0.050835  0.035357  0.022665    ...     0.022961  0.087012  0.090909   \n",
       "9  0.019608  0.008773  0.006346    ...     0.006647  0.205114  0.221196   \n",
       "\n",
       "         16        17        18        19        20        21        22  \n",
       "0  0.210444  0.157709  0.172879  0.210485  0.930261  0.046782  0.549743  \n",
       "1  0.156103  0.166871  0.222206  0.156147  0.963248  0.022804  0.629066  \n",
       "2  0.374253  0.311323  0.279111  0.374260  0.940123  0.033761  0.507133  \n",
       "3  0.162001  0.125000  0.159672  0.162018  0.924253  0.054377  0.577325  \n",
       "4  0.202422  0.149058  0.189117  0.202464  0.942339  0.034847  0.567561  \n",
       "5  0.272885  0.222768  0.231444  0.272896  0.773870  0.179311  0.412815  \n",
       "6  0.095549  0.079648  0.116804  0.095570  0.963839  0.019876  0.539439  \n",
       "7  0.205568  0.188165  0.231227  0.205609  0.971309  0.015771  0.591180  \n",
       "8  0.081865  0.068847  0.096020  0.081913  0.982944  0.009292  0.656934  \n",
       "9  0.185357  0.149928  0.201819  0.185400  0.988096  0.006465  0.690223  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementing algorithm \n",
    "#model 1 \n",
    "df1 = d_f.iloc[:,2:23]\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = d_f.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=d_f[754]\n",
    "X = array[:,2:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for fold validation,this code divides the data into splits, here we take 5 splits\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
    "# X is the feature set and y is the target\n",
    "for train_index, test_index in skf.split(X,y): \n",
    "    #print(\"Train:\", train_index, \"Validation:\", test_index) \n",
    "    X_train, X_test = X[train_index], X[test_index] \n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=10, random_state=0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.773763 (0.044156)\n",
      "CART: 0.747454 (0.059006)\n",
      "NB: 0.504930 (0.078200)\n",
      "RF: 0.760962 (0.053726)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=skf, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use all four algorithms on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,2:754]\n",
    "y= d_f[754]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  (0.7507814112800723, 0.04518662617984417)\n",
      "0.6628720511390827\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      0.66      0.56        38\n",
      "        1.0       0.87      0.76      0.81       112\n",
      "\n",
      "avg / total       0.77      0.73      0.75       150\n",
      "\n",
      "0.755232 (0.020306)\n",
      "AUC =  (0.8245665857973729, 0.04371154999832176)\n",
      "0.7092529037308732\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.61      0.57        38\n",
      "        1.0       0.86      0.83      0.85       112\n",
      "\n",
      "avg / total       0.78      0.77      0.78       150\n",
      "\n",
      "0.796284 (0.040743)\n",
      "AUC =  (0.8458493173880923, 0.04846063668461967)\n",
      "0.7290098043636155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.58      0.50      0.54        38\n",
      "        1.0       0.84      0.88      0.86       112\n",
      "\n",
      "avg / total       0.77      0.78      0.77       150\n",
      "\n",
      "0.837239 (0.037955)\n",
      "AUC =  (0.6808907053201416, 0.05922343444972462)\n",
      "0.6546394001420774\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      0.61      0.52        38\n",
      "        1.0       0.85      0.76      0.80       112\n",
      "\n",
      "avg / total       0.75      0.72      0.73       150\n",
      "\n",
      "0.738101 (0.056333)\n"
     ]
    }
   ],
   "source": [
    "def calculateAlogorithmAccuracy(model):\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "    import numpy as np\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    #from imblearn.metrics import geometric_mean_score           //Installation of library for gmean failed\n",
    "    from sklearn.metrics.cluster import fowlkes_mallows_score     #calculates gmean score\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=None)\n",
    "    testac = []\n",
    "    # # X is the feature set and y is the target\n",
    "    for train_index, test_index in skf.split(X,y): \n",
    "        X_train, X_test = X[train_index], X[test_index] \n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        clf = model\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "        testac.append(accuracy_score(y_test, preds))\n",
    "        \n",
    "    results = model_selection.cross_val_score(model, X, y, cv=skf, scoring='roc_auc')\n",
    "    \n",
    "    print(\"AUC = \",(results.mean(),results.std()))\n",
    "    classreport = classification_report(y_test, preds)\n",
    "    print(fowlkes_mallows_score(y_test, preds, sparse=False))\n",
    "    #print(imblearn.metrics.geometric_mean_score(y_test, preds))\n",
    "    print(classreport)\n",
    "    print(\"%f (%f)\" % (np.mean(testac), np.std(testac)))\n",
    "\n",
    "calculateAlogorithmAccuracy(GaussianNB())\n",
    "calculateAlogorithmAccuracy(RandomForestClassifier(n_estimators=10, random_state=0))\n",
    "calculateAlogorithmAccuracy(LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "calculateAlogorithmAccuracy(DecisionTreeClassifier())\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,2:23]\n",
    "y= d_f[754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  (0.6990072505122575, 0.049750954746173824)\n",
      "0.5850801826464546\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.29      0.82      0.43        38\n",
      "        1.0       0.84      0.33      0.47       112\n",
      "\n",
      "avg / total       0.70      0.45      0.46       150\n",
      "\n",
      "0.480105 (0.059528)\n",
      "AUC =  (0.7179552331304777, 0.051297796367230676)\n",
      "0.6787994839129398\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      0.45      0.45        38\n",
      "        1.0       0.81      0.82      0.82       112\n",
      "\n",
      "avg / total       0.72      0.73      0.73       150\n",
      "\n",
      "0.751276 (0.020431)\n",
      "AUC =  (0.7400778366952098, 0.05672358269165912)\n",
      "0.7345501636462712\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.38      0.13      0.20        38\n",
      "        1.0       0.76      0.93      0.84       112\n",
      "\n",
      "avg / total       0.66      0.73      0.67       150\n",
      "\n",
      "0.767092 (0.044119)\n",
      "AUC =  (0.6495921346934389, 0.043353682474882256)\n",
      "0.6253793900852724\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.29      0.29      0.29        38\n",
      "        1.0       0.76      0.76      0.76       112\n",
      "\n",
      "avg / total       0.64      0.64      0.64       150\n",
      "\n",
      "0.722092 (0.050872)\n"
     ]
    }
   ],
   "source": [
    "calculateAlogorithmAccuracy(GaussianNB())\n",
    "calculateAlogorithmAccuracy(RandomForestClassifier(n_estimators=10, random_state=0))\n",
    "calculateAlogorithmAccuracy(LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "calculateAlogorithmAccuracy(DecisionTreeClassifier())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,23:34]\n",
    "y= d_f[754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  (0.7394751557245736, 0.06907449109051654)\n",
      "0.6105132637777863\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.41      0.68      0.51        38\n",
      "        1.0       0.86      0.67      0.75       112\n",
      "\n",
      "avg / total       0.75      0.67      0.69       150\n",
      "\n",
      "0.666646 (0.100024)\n",
      "AUC =  (0.7609875288118184, 0.03313652832815877)\n",
      "0.7175837048041547\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.53      0.42      0.47        38\n",
      "        1.0       0.82      0.88      0.84       112\n",
      "\n",
      "avg / total       0.74      0.76      0.75       150\n",
      "\n",
      "0.776434 (0.023952)\n",
      "AUC =  (0.7491091048758725, 0.033671347750387756)\n",
      "0.7545145835567337\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      0.21      0.31        38\n",
      "        1.0       0.78      0.95      0.85       112\n",
      "\n",
      "avg / total       0.73      0.76      0.72       150\n",
      "\n",
      "0.757969 (0.020326)\n",
      "AUC =  (0.6441974788912377, 0.029329679237261735)\n",
      "0.6824432635573431\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      0.42      0.44        38\n",
      "        1.0       0.81      0.83      0.82       112\n",
      "\n",
      "avg / total       0.72      0.73      0.72       150\n",
      "\n",
      "0.736768 (0.009781)\n"
     ]
    }
   ],
   "source": [
    "calculateAlogorithmAccuracy(GaussianNB())\n",
    "calculateAlogorithmAccuracy(RandomForestClassifier(n_estimators=10, random_state=0))\n",
    "calculateAlogorithmAccuracy(LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "calculateAlogorithmAccuracy(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,34:56]\n",
    "y= d_f[754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  (0.683661150408356, 0.018345503423907072)\n",
      "0.6946169670267763\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.26      0.32        38\n",
      "        1.0       0.78      0.87      0.82       112\n",
      "\n",
      "avg / total       0.68      0.71      0.69       150\n",
      "\n",
      "0.723540 (0.032639)\n",
      "AUC =  (0.6953499356372552, 0.048303535877896674)\n",
      "0.7031470165022189\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.42      0.46        38\n",
      "        1.0       0.81      0.86      0.83       112\n",
      "\n",
      "avg / total       0.73      0.75      0.74       150\n",
      "\n",
      "0.753978 (0.024650)\n",
      "AUC =  (0.7056469138298435, 0.028372708265588083)\n",
      "0.7680187790116487\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.08      0.14        38\n",
      "        1.0       0.76      0.97      0.85       112\n",
      "\n",
      "avg / total       0.69      0.75      0.67       150\n",
      "\n",
      "0.768451 (0.019034)\n",
      "AUC =  (0.6008846571841449, 0.019781797553213486)\n",
      "0.6440798649301306\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.41      0.47      0.44        38\n",
      "        1.0       0.81      0.77      0.79       112\n",
      "\n",
      "avg / total       0.71      0.69      0.70       150\n",
      "\n",
      "0.691778 (0.043732)\n"
     ]
    }
   ],
   "source": [
    "calculateAlogorithmAccuracy(GaussianNB())\n",
    "calculateAlogorithmAccuracy(RandomForestClassifier(n_estimators=10, random_state=0))\n",
    "calculateAlogorithmAccuracy(LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "calculateAlogorithmAccuracy(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,56:140]\n",
    "y= d_f[754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  (0.7298286453881471, 0.033252030283674044)\n",
      "0.5722070671730951\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.35      0.89      0.50        38\n",
      "        1.0       0.92      0.43      0.59       112\n",
      "\n",
      "avg / total       0.78      0.55      0.56       150\n",
      "\n",
      "0.573999 (0.031760)\n",
      "AUC =  (0.7781484269301573, 0.04232319821368395)\n",
      "0.6414310806716899\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.40      0.45      0.42        38\n",
      "        1.0       0.80      0.77      0.79       112\n",
      "\n",
      "avg / total       0.70      0.69      0.69       150\n",
      "\n",
      "0.790810 (0.054069)\n",
      "AUC =  (0.842917826816872, 0.020519160833938333)\n",
      "0.7478691588401248\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.42      0.50        38\n",
      "        1.0       0.82      0.91      0.86       112\n",
      "\n",
      "avg / total       0.77      0.79      0.77       150\n",
      "\n",
      "0.802898 (0.021917)\n",
      "AUC =  (0.6449228500113456, 0.01956065429498311)\n",
      "0.6092131830775798\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.37      0.50      0.42        38\n",
      "        1.0       0.81      0.71      0.75       112\n",
      "\n",
      "avg / total       0.69      0.65      0.67       150\n",
      "\n",
      "0.726048 (0.037137)\n"
     ]
    }
   ],
   "source": [
    "calculateAlogorithmAccuracy(GaussianNB())\n",
    "calculateAlogorithmAccuracy(RandomForestClassifier(n_estimators=10, random_state=0))\n",
    "calculateAlogorithmAccuracy(LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "calculateAlogorithmAccuracy(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,140:322]\n",
    "y= d_f[754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  (0.6630870541312437, 0.04946178036741529)\n",
      "0.6604365208214438\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.29      0.21      0.24        38\n",
      "        1.0       0.75      0.82      0.79       112\n",
      "\n",
      "avg / total       0.64      0.67      0.65       150\n",
      "\n",
      "0.658542 (0.140519)\n",
      "AUC =  (0.6249393640244246, 0.06687638415776043)\n",
      "0.655701606680524\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.30      0.24      0.26        38\n",
      "        1.0       0.76      0.81      0.78       112\n",
      "\n",
      "avg / total       0.64      0.67      0.65       150\n",
      "\n",
      "0.690496 (0.030921)\n",
      "AUC =  (0.6796130046013604, 0.07191535790050495)\n",
      "0.7314010565076584\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.20      0.05      0.08        38\n",
      "        1.0       0.74      0.93      0.83       112\n",
      "\n",
      "avg / total       0.61      0.71      0.64       150\n",
      "\n",
      "0.747302 (0.024079)\n",
      "AUC =  (0.5611179177521748, 0.024663005977307712)\n",
      "0.6242664937976544\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.33      0.37      0.35        38\n",
      "        1.0       0.78      0.75      0.76       112\n",
      "\n",
      "avg / total       0.67      0.65      0.66       150\n",
      "\n",
      "0.662707 (0.024854)\n"
     ]
    }
   ],
   "source": [
    "calculateAlogorithmAccuracy(GaussianNB())\n",
    "calculateAlogorithmAccuracy(RandomForestClassifier(n_estimators=10, random_state=0))\n",
    "calculateAlogorithmAccuracy(LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "calculateAlogorithmAccuracy(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,322:754]\n",
    "y= d_f[754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  (0.7430753534619395, 0.04473578518058519)\n",
      "0.6545896620933298\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.47      0.68      0.56        38\n",
      "        1.0       0.87      0.74      0.80       112\n",
      "\n",
      "avg / total       0.77      0.73      0.74       150\n",
      "\n",
      "0.765854 (0.029966)\n",
      "AUC =  (0.793463065423941, 0.04192803604648375)\n",
      "0.7604083525677524\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.66      0.50      0.57        38\n",
      "        1.0       0.84      0.91      0.88       112\n",
      "\n",
      "avg / total       0.80      0.81      0.80       150\n",
      "\n",
      "0.813521 (0.020743)\n",
      "AUC =  (0.812284103297727, 0.03950010179494153)\n",
      "0.7767553083654336\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.50      0.58        38\n",
      "        1.0       0.85      0.93      0.89       112\n",
      "\n",
      "avg / total       0.81      0.82      0.81       150\n",
      "\n",
      "0.841309 (0.033010)\n",
      "AUC =  (0.6528189304097549, 0.04294703617820789)\n",
      "0.7558702047991505\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.64      0.61      0.62        38\n",
      "        1.0       0.87      0.88      0.88       112\n",
      "\n",
      "avg / total       0.81      0.81      0.81       150\n",
      "\n",
      "0.759373 (0.036380)\n"
     ]
    }
   ],
   "source": [
    "calculateAlogorithmAccuracy(GaussianNB())\n",
    "calculateAlogorithmAccuracy(RandomForestClassifier(n_estimators=10, random_state=0))\n",
    "calculateAlogorithmAccuracy(LogisticRegression(solver='liblinear', multi_class='ovr'))\n",
    "calculateAlogorithmAccuracy(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 40\n",
      "Selected Features: [False False False False False False False False  True False  True False\n",
      "  True  True  True  True  True  True False False False False False False\n",
      " False  True False False False False  True  True False False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False  True False False False False  True False False False\n",
      " False False  True False False False False False False False False  True\n",
      " False False False  True False False False False False False False False\n",
      "  True False  True False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False  True False False  True\n",
      " False False False  True False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True False False False False False False False  True False False False\n",
      " False False False False False  True False  True False False False  True\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False  True False False False False]\n",
      "Feature Ranking: [393 392 391 390 389 388 387 386   1   2   1   3   1   1   1   1   1   1\n",
      "  16   7  15   4   8  10  23   1  34  31  17  35   1   1  43  25   1  52\n",
      "  50  40  36  42  59  53  61  54  55  58   1  73  64  44  68  72  57  77\n",
      "  69  71  79  99   1  83 100  90  92   1 110  49  96  48   1  93 105  95\n",
      " 126 123   1 132 113 134 127 102 115 144 106   1 131 103 108   1 121 135\n",
      " 147 150 149 145 137 158   1 152   1 173 155 151 174 170   1 175 161 181\n",
      " 183 187 189 191 193 196 195 205 197 200 198 185 209 210 207 163 141 211\n",
      " 218 221 223 217 230 244 225   1 233 213 239 166 241 245 247 248 251 216\n",
      " 255 259 227 261 253 265 267 270 231 273 275 263 277 281 283 285 287 168\n",
      "   1 293 295 269 299 300 291 307 309 303 311 313 315 320 317 321 305 257\n",
      " 279 329 289 343   1 297 238 237 186   1 323 325 327 331 333 335 337 339\n",
      " 341 342 347 348 351 353 374 355 357 359 361 363 365 367 369 371 375 377\n",
      " 379 381 383 385 384 382 380 376 373 372 370 368 366 364 362 360 358 354\n",
      " 352 350 346 340 338 336 334 332 330 328 326 324 322 319 318 316 314 312\n",
      " 310 308 306 304 302 298 296 294 292 290 288 286 284 282 280 278 276 274\n",
      " 272 268 266 264 262 260 258 256 254 252 250 246 243 242 240 232 236 229\n",
      " 228 226 224 222 220 215 214 212 169 208 206 204 194 192 190 188   1 184\n",
      " 182 180  30  19  24  21  12  11   9  27  14  28  13  45   1  37  18   1\n",
      "  33  39  38   1  47  51   6  65  75  56  20  29   1  32  41  70  46  86\n",
      "  74  81  87  82  80 107  22  91  78  97  94  85  26  66  76 111  60   1\n",
      "   1 138 101  98  89 112  88 104   1  84  62 109 118 124 119  63 120   1\n",
      " 122   1 116 128  67   1 129 125   1 133 157 139 136 114 142 143 130 159\n",
      " 156 203 201 153 171 146 349 154 271 202 140 176 177 160 199 219 117 249\n",
      " 165 301 167 172 178 164 234 179 235 162   1 148   5   1 344 345 356 378]\n",
      "AUC =  (0.6408856659176874, 0.04922147126539599)\n",
      "0.6892450602878859\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.50      0.53      0.51        38\n",
      "        1.0       0.84      0.82      0.83       112\n",
      "\n",
      "avg / total       0.75      0.75      0.75       150\n",
      "\n",
      "0.744741 (0.023142)\n"
     ]
    }
   ],
   "source": [
    "input_data = array[:,322:754]\n",
    "target = d_f[754]\n",
    "\n",
    "def algoAccuracyOnSelectedFeatures(model, input_data, target, num_features):\n",
    "    from sklearn.feature_selection import RFE\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    import numpy\n",
    "    X = input_data\n",
    "    Y = target\n",
    "    rfe = RFE(model, num_features)\n",
    "    fit = rfe.fit(X, Y)\n",
    "    print(\"Num Features: %d\" % fit.n_features_)\n",
    "    print(\"Selected Features: %s\" % fit.support_)\n",
    "    print(\"Feature Ranking: %s\" % fit.ranking_)\n",
    "    X=rfe.fit_transform(X,Y)\n",
    "    calculateAlogorithmAccuracy(model)\n",
    "    \n",
    "algoAccuracyOnSelectedFeatures(DecisionTreeClassifier(), input_data, target, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = array[:,2:754]\n",
    "target = d_f[754]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 40\n",
      "Selected Features: [False  True False  True  True  True  True  True  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False  True False False False  True False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False  True  True False\n",
      " False False False False  True False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False  True False False  True False False False False  True False\n",
      " False False False False  True False False False False  True False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      "  True False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False  True False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True False False False False False False\n",
      " False False False False False False False False]\n",
      "Feature Ranking: [713   1   2   1   1   1   1   1   1   4   3   6   7  12  10   8  15  14\n",
      "  20  24  13   9  25  35  26  27  41  31   1  47  46  38  21  23  44  36\n",
      "  52  51  48  57  50  61  55  72  60  63   1  74  68  78  82  79  84  83\n",
      "  87  73  75  90   1 110  99  71  95   1 100 114 103   1 117 120 119 125\n",
      " 123 128 137 140 127 131 133 141 142 145   1 138 148 154 151 153 157 159\n",
      " 163 161 165 169 167 171 173 175 177 178 180 183 199 186 185 191 192 194\n",
      " 196   1 201 205 203 207 209 211 213   1   1 187 221 224 225 227   1 230\n",
      " 233 234 237 239 241 243 244 247 249   1 253 150 258 259 255 263 265 267\n",
      " 269 271 273 228 275 279 281 285 283 289 278 291 293 250 262 299 301 303\n",
      " 305 307 309 288 295 315 318 321 319 324 327 297 329 332 325 313 337 343\n",
      " 336 341 344 349 347 333 353 355 357 358 312 351 364 359 361 365 339 369\n",
      " 367 371 373 377 375 379 381 385 383 388 391 387 395 393 397 399 401 405\n",
      " 403 407 409 411 413 415 417 419 421 425 424 428 430 432 435 436 438 440\n",
      " 442 444 446 448 449 452 454 457 459 461 462 464 472 463 469 481 479 483\n",
      " 467 487 489 491 493 495 497 499 501 486 505 509 507 504 513 515 517 519\n",
      " 521 523 525 527 529 531 533 537 535 538 511 475 473 539 541 552 543 547\n",
      " 545 478 553 555 557 560 559 563 567 568 565 571 582 581 575 573 583 577\n",
      " 585 587 589 591 593 595 598 605 608 607 599 601 610 613 615 609 619 621\n",
      " 617 625 632 623 627 629 597 635 637 641 648 643 645 639 649 580 653 655\n",
      " 659 657 671 663 661 665 667 670 669 579 633 651 477 549 673 675 677 679\n",
      " 681 683 685 687 689 691 693 695   1 699 701 703 705 707 709 711 712 710\n",
      " 708 706 704 702 700 698 668 666 664 662 660 658 656 654 652 650 647 646\n",
      " 644 642 640 638 636 634 631 630 628 626 624 622 620 618 616 614 612 603\n",
      " 606 604 602 600   1 596 594 592 590 588 586 584 423   1 578 576 574 572\n",
      " 570 566 564 562 558 556 554 551 550 548 546 542 540   1 536 534 532 530\n",
      " 528 526 524 522 520 518 516 514 512 510 508 506 503 502 500 498 496 494\n",
      " 492 490 488 485 484 482 480   1 476 474 471 470 468 466   1 460 458 456\n",
      " 434 422 420 418 416 414 412 410 408 406 404 402 400 398 396 394 392 390\n",
      " 386 384 382 380 378 376 374 372 370 368 366 363 362 360   1 356 354 352\n",
      " 350 348 346 342 340 338 335 334   1  17  18   1  29  19  16  22   1  11\n",
      "  30  28  33  37   1  39  53  42  43   1  45   1  54  49  56   5  59  62\n",
      "  66  67  69  70  65  76  64  80  81  85  77  88  89  92  91  86  94  96\n",
      "  97  93  98 102 112 105 115 101 106 104 108 107 109  40   1 118 116 122\n",
      "  34 126 143 124 111 130 134 135 132  58 155 139 144 146  32 149 156 158\n",
      " 160 162 164 168 179 181 152 188 189 193   1 195   1 174 176 184 172 182\n",
      " 190   1 198 202 200 204 219 206 210 208 215 212 113 216 121 129 222 223\n",
      " 220 226 136 147 232 197 236 240 238 242 166 246 248 229 252 256 254 257\n",
      " 261 260 264 266 268 270 272 274 276 277 282 284 280 286 287 290 292 294\n",
      " 296 300 298 304 302 306 308 310 314 231 345 316 235 322 245   1 326 330\n",
      " 328 251 218   1 427 429 431 433 311 317 389 437 544 426 320 323 331   1\n",
      " 455 465 439 441 611 443 445 447 450 451 453 217 214 561 569 170   1   1\n",
      " 672 674 676 678 680 682 684 686 688 690 692 694 696 697]\n",
      "AUC =  (0.6382019975056771, 0.0426506095771998)\n",
      "0.6753454942234374\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.46      0.47      0.47        38\n",
      "        1.0       0.82      0.81      0.82       112\n",
      "\n",
      "avg / total       0.73      0.73      0.73       150\n",
      "\n",
      "0.731443 (0.035148)\n"
     ]
    }
   ],
   "source": [
    "algoAccuracyOnSelectedFeatures(DecisionTreeClassifier(), input_data, target, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
